---
layout: default
title: Getting started with Splout SQL
---
<div class="page-header">
  <h2 style="align:center;">Getting started with Splout SQL</h2>
</div>

<h3>Installing Splout</h3>


    <p>You need to have Java => 1.6 preinstalled. Download a release
    of Splout from Maven Central:</p>
    <ul>
        <li><strong>splout-*-mr2</strong> version for Hadoop &gt;= 2.X (YARN)</li>
        <li><strong>splout-*-mr1</strong> version for Hadoop &lt; 2.X</li>
        <li>Others (cdh5, etc) for your particular Hadoop distribution</li>
    </ul>

    <div class="alert alert-info">
        <strong>Other distros:</strong>
        We don't provide builds for every existing Hadoop distribution and version. If you need
        Splout working for your distro, you'll probably need to recompile Splout adapting a few dependencies.
        You can have a look to cdh5 profile at the different pom.xml to have a reference.
    </div>

    <div class="row">
    <div class="span4"></div>
    <div class="span4">
        <a class="btn btn-large btn-block btn-primary"
           href="http://search.maven.org/#browse%7C-1223190492" target='_blank'>Download Splout</a>
    </div>
    <div class="span4"></div>
    </div>

    <p>After that, you just need to decompress it.</p>

    <h4>Environmental variables</h4>
        You'll need to set properly a few environmental variables (i.e. at ~/.bashrc)

        <h5>For Hadoop &gt;= 2.X (YARN)</h5>
        <div class="row">
        <div class="span1"></div>
        <div class="span10">
        <table class="table table-bordered">
            <tbody>
                <tr>
                    <td>
                        SPLOUT_HADOOP_COMMON_HOME
                    </td>
                    <td>
                        Pointing to the folder where the hadoop-common-*.jar can be found
                    </td>
                </tr>
                <tr>
                    <td>
                        SPLOUT_HADOOP_HDFS_HOME
                    </td>
                    <td>
                        Pointing to the folder where where the hadoop-mapreduce-client-*.jar can be found
                    </td>
                </tr>
                <tr>
                    <td>
                        SPLOUT_HADOOP_MAPRED_HOME
                    </td>
                    <td>
                        Pointing to the folder where the hadoop-common-*.jar can be found
                    </td>
                </tr>
                <tr>
                    <td>
                        SPLOUT_HADOOP_CONF_DIR
                    </td>
                    <td>
                        <strong>Optional:</strong> Optionally, specify the Hadoop configuration folder (e.g. /etc/hadoop/conf). Will default to SPLOUT_HADOOP_MAPRED_HOME/conf
                    </td>
                </tr>
            </tbody>
        </table>
        </div>
        <div class="span1"></div>
        </div>

        <div class="row">
            <div class="span1"></div>
            <div class="span10">
                <div class="alert alert-info">
                    <p><strong>Example of env variables for Cloudera CDH5 using parcels</strong></p>
                    <pre><tt>export SPLOUT_HADOOP_COMMON_HOME=/opt/cloudera/parcels/CDH/lib/hadoop
                        export SPLOUT_HADOOP_HDFS_HOME=/opt/cloudera/parcels/CDH/lib/hadoop-hdfs
                        export SPLOUT_HADOOP_MAPRED_HOME=/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce
                        export SPLOUT_HADOOP_CONF_DIR=/etc/hadoop/conf</tt></pre>
                </div>
            </div>
            <div class="span1"></div>
        </div>


        <h5>For Hadoop &lt; 2.X</h5>
            <div class="row">
            <div class="span1"></div>
            <div class="span10">

            <p><strong>HADOOP_HOME</strong> must be properly defined pointing to your Hadoop installation folder.</p>

            </div>
            <div class="span1"></div>
            </div>

<h3 id="running">Running a local cluster</h3>

<p>The best thing for getting started with Splout is launching a local server in your machine:</p>

<pre><tt>bin/splout-service.sh qnode start
bin/splout-service.sh dnode start
</tt></pre>

<p>Now, if everything went fine, and assuming you had nothing running on port 4412 before, you will see a
  nice panel in <a href='http://localhost:4412' target='_blank'>localhost:4412</a> like this:</p>

<center><img src="img/Panel.png"/></center>

<p>Notice how there is no tablespace loaded in the system. That is expected, we will load an example one
  later. In logs/ folder you will find the logs of both the QNode and the DNode service. You can shutdown
  the services anytime with:</p>

<pre><tt>bin/splout-service.sh qnode stop
bin/splout-service.sh dnode stop
</tt></pre>

<div class="page-header" id="loading">
  <h2 style="align:center;">Loading an example dataset</h2>
</div>

<p>Splout comes with a few examples, one of which consists of miscellaneous world facts. We will load it
  and play with it to get used to the system and its behavior.</p>
<p>First, upload to HDFS the examples folder, as it contains the input files for all examples.</p>

<pre><tt>hadoop fs -put examples examples
</tt></pre>

<h3>Single Table Loading:</h3>

<p>Load the table city from the CSV file city.csv and use the country_code field to partition it into 4
  partitions:</p>

<pre><tt>hadoop jar splout-*-hadoop*.jar simple-generate --input examples/world/city.csv --output \
  database-files --tablespace city_pby_country_code --table city --separator , --escape \\ --quotes \
  \"\"\" --nullstring \\N --schema \
  "id:int,name:string,country_code:string,district:string,population:int" --partitionby country_code \
  --partitions 4
</tt></pre>

<p>Finally, deploy the results into Splout, using replication 2. That is, there will be 2 replicas per
  each partition:</p>

<pre><tt>hadoop jar splout-*-hadoop*.jar deploy --root database-files --tablespaces city_pby_country_code \
  --replication 2 --qnode http://localhost:4412
</tt></pre>

<p>In this particular example, as you have only one dnode, replication will be adjusted automatically to
  1. Look at the panel to see the information of the created tablespace:</p>

<pre><tt><a href='http://localhost:4412/tablespace.html?tablespace=city_pby_country_code'
            target='_blank'>http://localhost:4412/tablespace.html?tablespace=city_pby_country_code</a>
</tt></pre>

<p>Particularly, look at how partitions has been distributed using different country_code ranges. Now,
  you can launch some queries at the query console:</p>

<pre><tt><a href='http://localhost:4412/console.html'
            target='_blank'>http://localhost:4412/console.html</a>
</tt></pre>

<p>Perform the following query to show all the tables in the tablespace:</p>

<table class="table">
  <thead>
  <th>Tablespace</th>
  <th>Partition key</th>
  <th>Query</th>
  </thead>
  <tbody>
  <tr>
    <td>city_pby_country_code</td>
    <td>(empty)</td>
    <td>SELECT * FROM sqlite_master WHERE type='table';</td>
  </tbody>
</table>

<p>Now, let's find the cities with country_code</p>

<table class="table">
  <thead>
  <th>Tablespace</th>
  <th>Partition key</th>
  <th>Query</th>
  </thead>
  <tbody>
  <tr>
    <td>city_pby_country_code</td>
    <td>JPN</td>
    <td>SELECT * FROM city WHERE country_code = "JPN"</td>
  </tbody>
</table>

<p>Note that the shard 2 (partition 2) was hit. That is because we provided "JPN" as partition key.
  Otherwise, a wrong partition would have been hit, and no results would have been presented. Perform a
  test. Repeat the query, but keep the partition key empty. You'll see no results and partition 0 being
  hit.</p>
<p>The former query can be performed just using the REST Splout SQL interface. For the former query the
  URL would be the following:</p>

<pre><tt><a
    href='http://localhost:4412/api/query/city_pby_country_code?key=JPN&sql=SELECT%20*%20FROM%20city%20WHERE%20country_code%20%3D%20%22JPN%22'
    target='_blank'>http://localhost:4412/api/query/city_pby_country_code?key=JPN&sql=SELECT%20*%20FROM%20city%20WHERE%20country_code%20%3D%20%22JPN%22</a>
</tt></pre>

<h3>Multiple Tables:</h3>

<p>Multiple tables per tablespace are allowed. But all of them must be partitioned by the same key. We
  are going to create two different tablespaces:</p>

<br>

<h4>world-pby-country:</h4>

<table class="table">
  <tr>
    <td>country</td>
    <td>partitioned by country</td>
  </tr>
  <tr>
    <td>city</td>
    <td>partitioned by country_code</td>
  </tr>
  <tr>
    <td>country_language</td>
    <td>full table present in all partitions</td>
  </tr>
</table>

<br>

<h4>world-pby-continent-region:</h4>

<table class="table">
  <tr>
    <td>country</td>
    <td>partitioned by continent and region</td>
  </tr>
  <tr>
    <td>country_language</td>
    <td>full table present in all partitions</td>
  </tr>
</table>

<br>

<p>The structure of these tablespaces, and the the specification of the input data are in the files:
  <strong>world-pby-country.json</strong> and <strong>world-pby-continent-region.json</strong></p>
<p>Launch the following command to create both tablespaces:</p>

<pre><tt>hadoop jar splout-*-hadoop*.jar generate --output database-files --tablespacefile \
  examples/world/world-pby-country.json --tablespacefile examples/world/world-pby-continent-region.json
</tt></pre>

<p>Have a look to the database-files folder:</p>

<pre><tt>hadoop fs -ls database-files
</tt></pre>

<p>At this point, the tablespace files have been created, but they are not still present at Splout SQL.
  We have to deploy them. We can deploy both tablespaces at the same time atomically, so we can be sure
  that information between tablespaces will be consistent. Whichever of the following command performs
  the deploy of the tablespaces.</p>

<pre><tt>hadoop jar splout-*-hadoop*.jar deploy -root database-files -ts world-pby-continent-region -ts world-pby-country -r 2 -q http://localhost:4412</tt></pre>

<pre><tt>hadoop jar splout-*-hadoop*.jar deploy --config-file examples/world/deployment.json --qnode http://localhost:4412</tt></pre>

<p>Now both tablespaces should be present at Splout SQL. Have a look to the console.</p>

<br>

<p>You can also check out the following queries:</p>

<br>

<table class="table">
  <thead>
  <th></th>
  <th>Tablespace</th>
  <th>Partition key</th>
  <th>SQL Query</th>
  </thead>
  <tbody>
  <tr>
    <td>All Japan Languages:</td>
    <td>world-pby-country</td>
    <td>JPN</td>
    <td>SELECT country_language.* FROM country, country_language WHERE country.code =
      country_language.country_code AND country.code = "JPN"
    </td>
  </tr>
  <tr>
    <td>Distinct districs in Japan:</td>
    <td>world-pby-country</td>
    <td>JPN</td>
    <td>SELECT country.name, count(distinct district) as num_districts FROM country, city WHERE
      country.code = "JPN" and country.code = city.country_code
    </td>
  </tr>
  <tr>
    <td>Population of Western Europe:</td>
    <td>world-pby-continent-region</td>
    <td>EuropeWestern Europe</td>
    <td>SELECT continent,region,sum(population) total_population FROM country WHERE continent = "Europe"
      AND region = "Western Europe";
    </td>
  </tr>
  <tr>
    <td>Biggest countries on Central Africa:</td>
    <td>world-pby-continent-region</td>
    <td>AfricaCentral Africa</td>
    <td>SELECT name, surface_area FROM country WHERE continent = "Africa" AND region = "Central Africa"
      ORDER BY surface_area DESC;
    </td>
  </tr>
  <tr>
    <td>Most talked languages on Central Africa:</td>
    <td>world-pby-continent-region</td>
    <td>AfricaCentral Africa</td>
    <td>SELECT language, sum((percentage/100)*population) as people FROM country, country_language WHERE
      country.code = country_language.country_code AND continent = "Africa" AND region = "Central Africa"
      GROUP BY language ORDER BY people DESC;
    </td>
  </tr>
  </tbody>
</table>

<br>

<p>Note that all the queries presented before are compatible with the partitioning decided for the
  tablespace. Otherwise they would have not worked properly. Also, be careful to properly define the
  needed indexes in order to answer queries fast.</p>
